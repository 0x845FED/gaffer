dependency graph rules :

	* if context changes, then it's the responsibility of the observer to update to new values
	  by calling ValuePlug::getValue()
		- potentially every node has changed so this must be done for all nodes being observed
			- perhaps at a later date we can propagate a contextMask through the graph
				- this would let us know if a given node will change when a given piece
				  of context changes. 
				- or perhaps that will be unecessary, if we can compute the hash and do a cache
				  lookup quick enough, we'll quickly just retrieve the already computed value
				  where possible
		- ValuePlug must recognise that a new computation (or cache retrieval) is required
			- currently the clean status is preventing that
				- is a first good step to remove the clean flag and compute on every getValue()
					- and then see caching as an optimisation?
				  
	* if an input plug changes, we can dirty all its dependencies, signalling to observers
	  that the values may have changed. this can be limited to just the portion of the
	  graph affected.
	  	- do we store the dirty state?
	  		- if we do it must be stored per context.

	* what does the dirty flag mean now?
		- it must either be ditched, or stored once per context
		- if stored once per context
			- we cannot cache every value for ever
				- therefore dirty would have to mean "in the cache"
					- but that changes at arbitrary times
					- and isn't very useful
		- i think we must ditch it
			- we'll still have the signal though.
				- although that should be merged with the value set signal.
		- we should remove Node::dirty() and replace it with Node::affects()
			- this way we can remove the setDirty() call, and use affects() for
			  doing nice traversals of the graph at other times
			- affects() can then be accompanied by a requires() method which does the reverse
				- this is used to do reverse traversals, compute hashes and precompute inputs

	* caching
		- compute the hash of the input plugs, and the hash of the valid pieces of the context
			- now we need to know which inputs are needed by an output (for hashing) in addition
			  to needing to know which outputs are affected by an input (for dirtying)
				- is it time to store this explicitly on the Plugs?
				
	* threading
		
		- each thread has a context stack of its own
			- so different threads can compute different things and in different contexts
		
		- we would like to compute the inputs to a process in parallel before performing the
		  process
		  	- we can do this if we know what the inputs are
		  	- inputs may be needed multiple times and at different contexts
		  	- we will need to make sure these values don't drop out of the cache before
		  	  computation is over
		  	- we still want the compute() function to just call plug.getValue() when it
		  	  gets the wanted value
		  	  
		- observers need not to block when requesting an up-to-date value
			- they just want to be signalled when it's ready
				- we need to make sure it doesn't disappear from the cache before they
				  get it
				  
			- because the ui won't block, values might be changed/connections broken
			  etc while we're computing on another thread
			  	- in this case we want to abort the computation
			  		- Node needs to be able to query aborted status
			  			- and perhaps Plug get/set value should throw when Node
			  			  is aborted.
			  			  
		- ValuePlug will need thread-specific storage specifying the Plug being
		  computed, references to the input values, and a flag saying whether or
		  not the computation should be aborted.
		  
	* signals
	
		- it's not yet clear whether or not signals should be emitted for plug changes
		  during computation
		  
	* storage. value plugs need access to storage at the following points :
	
		- in setValue()
			- needs readable (but not updated) previous value to do lazy signalling
			- needs writable value to set new value
			- setValue is called in several ways 
				- statically by an outside influence
					- must support undo, and we should know that the value in storage
					  is up to date already
				- from compute() to set the result
					- must /not/ support undo, and we should know that the value in
					  storage is junk
					
		- in setValueInternal()
			- needs writable value only
			
		- in getValue()
			- needs updated readable() value
			- this currently calls computeIfNeeded()
			
		- 

geometry streams :

	* output plug doesn't carry values - just used to make connection
		- not true.
			- it'll have the geometry data in a cache, keyed by context
	* context object defines what is being worked on
		- time
		- attribute state
		- parent
		- path
		- image processing contexts would contain a tile index as well
		- contexts should be able to store arbitrary key/value pairs and
		  must be introspectable
	* children() method says what children there are
	* geometry() method or summink does the expansion
	* is it advantageous to have a separate attributes() method?
		- so things applying shaders don't cause geometry recomputation?
		- sounds good for fur systems
	* overrides are made by input nodes which compute different values
	  based on context
	  	- we'll also want to be able to make overrides by adding nodes downstream though
			- works better in a pipeline
ops :

	* output plug carries values?
		- for the current context?
	* need caching and evaluation at different contexts?
		- the only reason for this is inputs at different times
			- it's a good reason though
			
plugs :

	* storing output values on plugs is flawed?
		- because we need a value per context, per thread etc
		- or do we cache multiple values?
		- if it is then it's flawed to store values on the inputs
		  they are connected to too
	* probably need values to become ObjectPtr based
	
	* setValue() ?
		- it implies there's only one value
			- which is true only when the value is static and 
			  doesn't depend on context
		- doesn't make sense for anything with an input connection
			- because the input can have different values in different contexts
			- but we do want to be able to call setValue on plugs with
			  inputs from animation curves
		- compute() can definitely /not/ call setValue
		
			- unless we do something really cunning like this :
			
				with MyLovelyContext() :
				
					setValue()
					getValue()
					
				- that's potentially really nice no?
				- behind the scenes the context is used to key into
				  a dictionary of plug values.
	
	* need to better define dirtiness
		- because no one value for a plug is valid for all
		  contexts.
		- i think dirtiness will be more like "the previously computed
		  values for this plug may need to be recomputed"
		  	- or will it be "any values you got from the plug before you
		  	  need to get again now"?
		  	- regardless of which context they were in
		  		- and we use hashing and caches to skip the redundant
		  		  recomputations
		- let's start by having setDirty() clear all the caches
			- and have the cache key be only the context, not the plug values
			- really??
		- there's no such thing as clean any more, as we'll never have all the
		  values for all the contexts, or do we need a cleanliness per context?
	
		- i think plugSetSignal() and plugDirtiedSignal() will be merged and will just
		  mean "if you care about the value of this plug you should have another look"
	
time :

	* an element of the context
	* ScriptNode has a context which is used by all the uis by default
	  	  	  	
iteration :

	* we could do awesome stuff with an iterate node
		* which is maybe similar to a time convolve?
			* but perhaps modifying different parts of the context?
				* maybe a context has an iterationIndex member?

cortex changes needed :

	* Object::hash()
	* LRUCache unload functor - so we can ditch things to disk rather than have
	  to recompute every time

Nuke :
	
	- Totally awesome time handling
	- Good threading
	- But can't have outputs of simple types like float
	- Has to evaluate the entire graph of input plugs because there's
	  no concept of dirtiness for expressions etc.
	
Shake :

	- Terrible time handling, because the whole graph needs to be set
	  up for the time in question
	- Not good for threading
		- Again because the graph needs to be in the right state for the
		  current computation
	- Also can't have simple outputs depend on image inputs
	
Maya :

	- Not very good threading
	- Not very good time handling
	- But efficient updates for dirtiness of plugs